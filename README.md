# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The dataset contains information on direct marketing campaigns of a Portuguese financial institution. We seek to predict whether the client will subscribe a term deposit or not (variable `y`), making this a classification task.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

The best performing model was a VotingEnsemble that resulted from applying an AutoML job, creating a pipeline for preprocessing, training and testing 8 different models which ended up being ensembled by giving each a weight in the final prediction.

This ensemble is composed of 4 XGBoost Classifiers, 1 LightGBM Classifier, 1 Logistic Regression Classifier, 1 Support Vector Machine with Stochastic Gradient Descent training and 1 Random Forest Classifier.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
* We have a training script `train.py` that is responsible for the following:
  * Creating a `TabularDatasetFactory` from an online CSV file.
  * Data cleansing and one-hot encoding categorical data
  * Splitting the cleansed data in train and test subsets. We do this in order to score the model trained with the train set in a new set whose examples the model has not been trained on.
  * Training a Logistic Regression Classifier from the `scikit-learn` library. This model is used to explain the relationship between the target variable and the features contained in the dataset.
  * Saving the model as a pickle.
* This script takes two arguments, i.e. the two hyperparameters that can be tuned in this experiment.
  * The first is the `C` hyperparameter, which is the inverse of regularization strength.
  * The second is the `max_iter` hyperparameter, which is the maximum number of iterations to converge.
* In the notebook, we specified a hyperdrive job that will execute our `train.py` with different configurations automatically.
  * First we specified a parameter sampler so that the hyperdrive job knows which parameter range to explore.
  * Then we specified a policy for early stopping
  * Last, we specified the hyperdrive configuration and ran the experiment.

**What are the benefits of the parameter sampler you chose?**
It lets us randomly explore a hyperparameter space, saving a lot of time compared to an exhaustive, brute-force search.
* In our case we let the `C` parameter take a uniform distribution bounded to two values that we had previously narrowed from a past experiment.
* The `max_iter` parameter can be chosen from a given set as there is not much difference in the result when choosing consecutive values, so we are ok by exploring values ranging from 50 to 200 iterations that we eyeballed.

**What are the benefits of the early stopping policy you chose?**
We chose a `BanditPolicy`, that defines an early stopping policy based on slack criteria and a frequency and delay interval for evaluation.

We used the `slack_factor` instead of the `slack_amount` parameter. The `slack_factor` is the ratio used to calculate the allowed distance from the best performing run. We chose a value of 10%, so if in each time the policy is evaluated, the metric falls below the slack respect the best performing model, the job is terminated. This allows us to have a hyperdrive job that does not deplete its `max_total_runs` if the model is not improving with each iteration, therefore saving computing time.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
